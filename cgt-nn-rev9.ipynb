{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Методы исследования характеристических свойств нейронных сетей с применением теоретико-игрового подхода\n",
    "\n",
    "- **Теория**: И.В.Томилов ivan-tomilov3@yandex.ru\n",
    "- **Реализация**: М.А.Зайцева maria@tail-call.ru\n",
    "- **Поддержка CUDA**: А.Е.Григорьева admin@linkennt.ru\n",
    "- **Ревизия**: 9\n",
    "\n",
    "- **Другие ревизии**:\n",
    "  - С 1 по 7: [Яндекс Диск](https://disk.yandex.ru/d/aZozDpBlzh_z1A)\n",
    "  - 8 и далее: [GitHub releases page](https://github.com/LISA-ITMO/CGT4NN/releases)\n",
    "<!-- please do not append text into this block -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "> Gradient dropout - не все игроки не всегда получают выигрыш\n",
    "\n",
    "- [ ] Больше скрытых слоёв!\n",
    "    - [ ] В скрытых слоях 100-200 нейронов\n",
    "\n",
    "Для этого мы вводим класс `AugmentedReLUNetworkMultilayer`, который расширяет\n",
    "интерфейс `AugmentedReLUNetwork` параметром `hidden_layers_count`.\n",
    "\n",
    "- [ ] Взять датасет с плохим перфомансом\n",
    "- [ ] Применять gradient dropout к половине сети и ко всей сети\n",
    "- [ ] Варьировать шум от 0 до 1 (а не 2)\n",
    "- [x] $\\alpha \\in \\{ 1, 1.12, 2 \\}$\n",
    "- [ ] На задаче классификации заменять класс $q$ на класс $r$ с заданной вероятностью, а вещественный шум использовать только для регрессии.\n",
    "- [ ] Посмотреть, какой архитектурой решали MNIST character recognition на полносвязных сетях\n",
    "- [ ] Использовать sMAPE вместо $R^2$\n",
    "- [ ] Использовать инициализацию *He* вместо *Xavier*\n",
    "  - [ ] Сравнить\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TORCH_DEVICE is cpu\n"
     ]
    }
   ],
   "source": [
    "from cgtnnlib.constants import LEARNING_RATE, RANDOM_STATE\n",
    "import cgtnnlib.training as tr\n",
    "import cgtnnlib.datasets as ds\n",
    "from cgtnnlib.NoiseGenerator import target_dispersion_scaled_noise, stable_noise, no_noise_generator\n",
    "\n",
    "iterations = 10\n",
    "epochs = 10\n",
    "pp = [0.0, 0.5, 0.9]\n",
    "inner_layer_size = 150\n",
    "\n",
    "# datasets = ds.datasets\n",
    "\n",
    "datasets = [\n",
    "    # ds.datasets[0], # 1\n",
    "    ds.datasets['StudentPerformanceFactors'], # 3\n",
    "    # ds.datasets['allhyper'], # 4\n",
    "    # ds.datasets['wine_quality'], # 6\n",
    "]\n",
    "\n",
    "ng_makers = [\n",
    "    lambda _: no_noise_generator,\n",
    "    lambda dataset: target_dispersion_scaled_noise(\n",
    "        dataset=dataset,\n",
    "        factor=0.03,\n",
    "        random_seed=RANDOM_STATE + 1,\n",
    "    ),\n",
    "    lambda dataset: stable_noise(\n",
    "        dataset=dataset,\n",
    "        factor=0.03,\n",
    "        alpha=1,\n",
    "        beta=0,\n",
    "    ),\n",
    "    lambda dataset: stable_noise(\n",
    "        dataset=dataset,\n",
    "        factor=0.03,\n",
    "        alpha=1.12,\n",
    "        beta=0,\n",
    "    ),\n",
    "    lambda dataset: stable_noise(\n",
    "        dataset=dataset,\n",
    "        factor=0.03,\n",
    "        alpha=2.0,\n",
    "        beta=1,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Model B\n",
    "\n",
    "- both take ~5m 06s to train 10 iterations\n",
    "- both on both noises: about ~10m\n",
    "\n",
    "<hr>\n",
    "\n",
    "- `ds.datasets['StudentPerformanceFactors']` takes ~2m 30s to train 10 iterations\n",
    "- `ds.datasets['wine_quality']` takes ~2m 36s to train 10 iterations\n",
    "\n",
    "<hr>\n",
    "\n",
    "- `ds.datasets['allhyper']` takes ~36m to train on all noise generators\n",
    "\n",
    "### Model B*\n",
    "\n",
    "~20m: Dataset #3, 5 ng_makers, 3 pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=9 #3 gStable3A2.0B1F0.03 p=0.9 E9/10 S436 Loss=0.5415@AugmentedReLUNetworkMultilayer\n",
      "create_and_train_model(): saved model to rev9/dataset3_p0.9_noiseStable3A2.0B1F0.03/9.pth\n",
      "Report saved to rev9/dataset3_p0.9_noiseStable3A2.0B1F0.03/report.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from cgtnnlib.Report import Report\n",
    "from cgtnnlib.nn.AugmentedReLUNetworkMultilayer import AugmentedReLUNetworkMultilayer\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for ng_maker in ng_makers:\n",
    "        for p in pp:\n",
    "            noise_generator = ng_maker(dataset)\n",
    "            for iteration in range(iterations):\n",
    "                os.makedirs(f'rev9/dataset{dataset.number}_p{p}_noise{noise_generator.name}/', exist_ok=True)\n",
    "                report = Report(\n",
    "                    dir='rev9',\n",
    "                    filename=f'dataset{dataset.number}_p{p}_noise{noise_generator.name}/report.json'\n",
    "                )\n",
    "                tr.super_train_model(\n",
    "                    make_model=lambda: AugmentedReLUNetworkMultilayer(\n",
    "                        inputs_count=dataset.features_count,\n",
    "                        outputs_count=dataset.classes_count,\n",
    "                        p=p,\n",
    "                        inner_layer_size=inner_layer_size,\n",
    "                        hidden_layers_count=3,\n",
    "                    ),\n",
    "                    model_path=f'rev9/dataset{dataset.number}_p{p}_noise{noise_generator.name}/{iteration}.pth',\n",
    "                    dataset=dataset,\n",
    "                    report=report,\n",
    "                    epochs=epochs,\n",
    "                    learning_rate=LEARNING_RATE,\n",
    "                    dry_run=False,\n",
    "                    iteration=iteration,\n",
    "                    noise_generator=noise_generator,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "IndexError: Target 106 is out of bounds.\n",
    "\n",
    "        TORCH_CHECK_INDEX(\n",
    "            cur_target >= 0 && cur_target < n_classes,\n",
    "            \"Target \",\n",
    "            cur_target,\n",
    "            \" is out of bounds.\");\n",
    "```\n",
    "\n",
    "https://github.com/pytorch/pytorch/blob/4106aa33eb2946bf67f4ffd2ad9f2dcb52ed2384/aten/src/ATen/native/LossNLL.cpp#L192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнить эту ячейку для eval или следующую для loss.\n",
    "Чтобы всё отрисовалось, нужно запустить два раза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cgtnnlib.LearningTask import is_classification_task\n",
    "from cgtnnlib.analyze import plot_deviant_curves_on_ax_or_plt\n",
    "from cgtnnlib.constants import NOISE_FACTORS\n",
    "from cgtnnlib.evaluate import eval_report_at_path\n",
    "from cgtnnlib.nn.AugmentedReLUNetwork import AugmentedReLUNetwork\n",
    "\n",
    "\n",
    "\n",
    "def read_json(path: str) -> dict:\n",
    "    with open(path) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def summarize_series_list(series_list: list[pd.Series]):\n",
    "    df = pd.DataFrame(series_list).T\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        0.25: df.quantile(0.25, axis=1),\n",
    "        0.75: df.quantile(0.75, axis=1),\n",
    "        'mean': df.mean(axis=1),\n",
    "    })\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def make_ax_drawer(\n",
    "    read_json,\n",
    "    dataset,\n",
    "    ng_maker,\n",
    "    p,\n",
    "):\n",
    "    noise_generator = ng_maker(dataset)\n",
    "    prefix = (\n",
    "        f'cgtnn-{dataset.number}Y-AugmentedReLUNetwork'\n",
    "        +f'-g{noise_generator.name}-P{p}_'\n",
    "    )\n",
    "\n",
    "    def report_path(n):\n",
    "        return f'pth/{prefix}N{n}.json'\n",
    "\n",
    "    def model_path(n):\n",
    "        return f'pth/{prefix}N{n}.pth'\n",
    "\n",
    "    def read_eval_from_iteration(n) -> pd.DataFrame:\n",
    "        path = report_path(n)\n",
    "        eval_report_at_path(\n",
    "                    report_path=path,\n",
    "                    model_path=model_path(n),\n",
    "                    constructor=AugmentedReLUNetwork,\n",
    "                    dataset=dataset,\n",
    "                    p=p,\n",
    "                )\n",
    "        print('read_eval_from_iteration', path, n)\n",
    "        return pd.DataFrame(read_json(path)['eval'])\n",
    "    \n",
    "    def read_loss_from_iteration(n) -> pd.DataFrame:\n",
    "        path = report_path(n)\n",
    "        json = read_json(path)\n",
    "        return pd.DataFrame(json['loss'])\n",
    "\n",
    "    if is_classification_task(dataset.learning_task):\n",
    "        metric = 'roc_auc'\n",
    "    else:\n",
    "        metric = 'mse'\n",
    "\n",
    "    files = [\n",
    "        read_eval_from_iteration(n)\n",
    "        for n in range(iterations)\n",
    "    ]\n",
    "            \n",
    "    print(report_path(0))\n",
    "\n",
    "    curve = summarize_series_list([file[metric] for file in files])\n",
    "\n",
    "    def draw_ax(ax):\n",
    "        plot_deviant_curves_on_ax_or_plt(\n",
    "            ax_or_plt=ax,\n",
    "            models=[{\n",
    "                'curve': curve,\n",
    "                'color': 'purple',\n",
    "                'label': 'Среднее',\n",
    "                'quantiles_color': 'pink',\n",
    "                'quantiles_label': 'Квартили 0,25; 0,75', \n",
    "            }],\n",
    "            X=NOISE_FACTORS,\n",
    "            title='\\n'.join([\n",
    "                f'{noise_generator.name}, p = {p}',\n",
    "            ]),\n",
    "            xlabel='Шум на входе',\n",
    "            ylabel=metric,\n",
    "            quantiles_alpha=0.5,\n",
    "        )\n",
    "    \n",
    "    return draw_ax\n",
    "\n",
    "ax_drawers = [\n",
    "    [\n",
    "        [make_ax_drawer(read_json, dataset, ng_maker, p) for p in pp]\n",
    "        for ng_maker in ng_makers\n",
    "    ]\n",
    "    for dataset in datasets\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cgtnnlib.LearningTask import is_classification_task\n",
    "from cgtnnlib.analyze import plot_deviant_curves_on_ax_or_plt\n",
    "from cgtnnlib.constants import NOISE_FACTORS\n",
    "from cgtnnlib.evaluate import eval_report_at_path\n",
    "from cgtnnlib.nn.AugmentedReLUNetwork import AugmentedReLUNetwork\n",
    "\n",
    "\n",
    "\n",
    "def read_json(path: str) -> dict:\n",
    "    with open(path) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def summarize_series_list(series_list: list[pd.Series]):\n",
    "    df = pd.DataFrame(series_list).T\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        0.25: df.quantile(0.25, axis=1),\n",
    "        0.75: df.quantile(0.75, axis=1),\n",
    "        'mean': df.mean(axis=1),\n",
    "    })\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def make_ax_drawer(\n",
    "    read_json,\n",
    "    dataset,\n",
    "    ng_maker,\n",
    "    p,\n",
    "):\n",
    "    noise_generator = ng_maker(dataset)\n",
    "    prefix = (\n",
    "        f'cgtnn-{dataset.number}Y-AugmentedReLUNetwork'\n",
    "        +f'-g{noise_generator.name}-P{p}_'\n",
    "    )\n",
    "\n",
    "    def report_path(n):\n",
    "        return f'pth/{prefix}N{n}.json'\n",
    "\n",
    "    def model_path(n):\n",
    "        return f'pth/{prefix}N{n}.pth'\n",
    "\n",
    "    def read_eval_from_iteration(n) -> pd.DataFrame:\n",
    "        path = report_path(n)\n",
    "        eval_report_at_path(\n",
    "                    report_path=path,\n",
    "                    model_path=model_path(n),\n",
    "                    constructor=AugmentedReLUNetwork,\n",
    "                    dataset=dataset,\n",
    "                    p=p,\n",
    "                )\n",
    "        print('read_eval_from_iteration', path, n)\n",
    "        return pd.DataFrame(read_json(path)['eval'])\n",
    "    \n",
    "    def read_loss_from_iteration(n) -> pd.DataFrame:\n",
    "        path = report_path(n)\n",
    "        json = read_json(path)\n",
    "        return pd.DataFrame({ 'loss': json['loss'] })\n",
    "\n",
    "    metric = 'loss'\n",
    "\n",
    "    files = [\n",
    "        read_loss_from_iteration(n)\n",
    "        for n in range(iterations)\n",
    "    ]\n",
    "            \n",
    "    print(f'Processing {report_path(0)}...')\n",
    "\n",
    "    curve = summarize_series_list([file[metric] for file in files])\n",
    "\n",
    "    def draw_ax(ax):\n",
    "        plot_deviant_curves_on_ax_or_plt(\n",
    "            ax_or_plt=ax,\n",
    "            models=[{\n",
    "                'curve': curve,\n",
    "                'color': 'purple',\n",
    "                'label': 'Среднее',\n",
    "                'quantiles_color': 'pink',\n",
    "                'quantiles_label': 'Квартили 0,25; 0,75', \n",
    "            }],\n",
    "            X=curve.index,\n",
    "            title='\\n'.join([\n",
    "                f'{noise_generator.name}, p = {p}',\n",
    "            ]),\n",
    "            xlabel='Итерация',\n",
    "            ylabel=metric,\n",
    "            quantiles_alpha=0.5,\n",
    "        )\n",
    "    \n",
    "    return draw_ax\n",
    "\n",
    "ax_drawers = [\n",
    "    [\n",
    "        [make_ax_drawer(read_json, dataset, ng_maker, p) for p in pp]\n",
    "        for ng_maker in ng_makers\n",
    "    ]\n",
    "    for dataset in datasets\n",
    "]\n",
    "\n",
    "print(ax_drawers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(nrows, ncols) = (\n",
    "    len(ax_drawers[0]),\n",
    "    len(ax_drawers[0][0]),\n",
    ")\n",
    "\n",
    "(nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets):\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(15, 40))\n",
    "\n",
    "    for j in range(nrows):\n",
    "        for k in range(ncols):\n",
    "            ax_drawers[i][j][k](axes[j, k])\n",
    "    \n",
    "    fig.suptitle(f'Датасет #{dataset.number}: {dataset.name}\\nAugmentedReLUNetwork', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.95]) # rect adjusts space for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Chambers, J. M., Mallows, C. L., & Stuck, B. W. (1976). A method for simulating stable random variables. *Journal of the American Statistical Association*, *71*(354), 340-344.\n",
    "2. M. Firouzi, A. Mohammadpour. A Survey on Simulating Stable Random Variables. URL: https://www.semanticscholar.org/reader/11a1e93642dc0a5c94e6906bcca5e4d25d4e9d46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
