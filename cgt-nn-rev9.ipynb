{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–µ—Ç–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤–æ–π—Å—Ç–≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º —Ç–µ–æ—Ä–µ—Ç–∏–∫–æ-–∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞\n",
    "\n",
    "- **–¢–µ–æ—Ä–∏—è**: –ò.–í.–¢–æ–º–∏–ª–æ–≤ ivan-tomilov3@yandex.ru\n",
    "- **–†–µ–∞–ª–∏–∑–∞—Ü–∏—è**: –ú.–ê.–ó–∞–π—Ü–µ–≤–∞ maria@tail-call.ru\n",
    "- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ CUDA**: –ê.–ï.–ì—Ä–∏–≥–æ—Ä—å–µ–≤–∞ admin@linkennt.ru\n",
    "- **–†–µ–≤–∏–∑–∏—è**: 9\n",
    "\n",
    "- **–î—Ä—É–≥–∏–µ —Ä–µ–≤–∏–∑–∏–∏**:\n",
    "  - –° 1 –ø–æ 7: [–Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫](https://disk.yandex.ru/d/aZozDpBlzh_z1A)\n",
    "  - 8 –∏ –¥–∞–ª–µ–µ: [GitHub releases page](https://github.com/LISA-ITMO/CGT4NN/releases)\n",
    "<!-- please do not append text into this block -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DONE\n",
    "\n",
    "> Gradient dropout - –Ω–µ –≤—Å–µ –∏–≥—Ä–æ–∫–∏ –Ω–µ –≤—Å–µ–≥–¥–∞ –ø–æ–ª—É—á–∞—é—Ç –≤—ã–∏–≥—Ä—ã—à\n",
    "\n",
    "- [x] –ë–æ–ª—å—à–µ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤! (—Ç–µ–ø–µ—Ä—å –∏—Ö 5)\n",
    "    - [x] –í —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö 100-200 –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "    - [x] –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —á—Ç–æ-—Ç–æ –∫—Ä–æ–º–µ 3 —Å–ª–æ—ë–≤\n",
    "\n",
    "–î–ª—è —ç—Ç–æ–≥–æ –º—ã –≤–≤–æ–¥–∏–º –∫–ª–∞—Å—Å `AugmentedReLUNetworkMultilayer`, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—à–∏—Ä—è–µ—Ç\n",
    "–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å `AugmentedReLUNetwork` –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `hidden_layers_count`.\n",
    "\n",
    "- [x] –í–∑—è—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å –ø–ª–æ—Ö–∏–º –ø–µ—Ä—Ñ–æ–º–∞–Ω—Å–æ–º\n",
    "    - [x] –ö–∞–∫–æ–π –∂–µ –∏–∑ –Ω–∏—Ö —Å –ø–ª–æ—Ö–∏–º –ø–µ—Ä—Ñ–æ–º–∞–Ω—Å–æ–º? –†–∞–∑–≤–µ –Ω–µ –≤—Å–µ?\n",
    "      - –Ø –¥—É–º–∞—é, —á—Ç–æ #4, –µ–≥–æ $R^2$ –Ω–∏–∂–µ -15\n",
    "    - $R^2$ —É–≤–µ–ª–∏—á–∏–ª—Å—è —Å -15 –¥–æ -2 üéâ\n",
    "- [x] $\\alpha \\in \\{ 1, 1.12, 2 \\}$\n",
    "- [x] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sMAPE –≤–º–µ—Å—Ç–æ $R^2$\n",
    "\n",
    "## TODO\n",
    "\n",
    "- [ ] –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –≤ SMAPe\n",
    "- [ ] –ï—Å–ª–∏ Y -> R —ç—Ç–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, —Ç–æ –ø–ª–æ—Ö–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å\n",
    "\n",
    "Best Response: —à–∞–≥ –≤ —Å—Ç–æ—Ä–æ–Ω—É –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞\n",
    "\n",
    "–ö–∞–∫ —Å–¥–µ–ª–∞—Ç—å –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–∞–ª—å–Ω–µ–µ - —Ñ—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏ —ç—Ç–æ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π –≤–∏–¥ —Å–ª–æ—è\n",
    "\n",
    "–ü—Ä–∏–Ω–∏–º–∞—Ç –≤—ã—Ö–æ–¥ —Å–µ—Ç–∫–∏, –æ—Ç–¥–∞—ë—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç –ª–æ—Å—Å —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "\n",
    "–í —ç—Ç–æ–º —Å–ª—É—á–∞–µ —É –Ω–∞—Å –≤–µ—Å—å –º–µ—Ö–∞–Ω–∏–∑–º –∑–∞–º—ã–∫–∞–µ—Ç—Å—è, –∞ –∑–∞–º–∫–Ω—É—Ç–æ–π –∏ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–π –∏ –æ–±—É—á–∞–µ–º–æ–π –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏\n",
    "\n",
    "- [ ] –ü—Ä–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ –æ—Ç–∫—Ä—ã—Ç—É—é –∏–≥—Ä—É\n",
    "\n",
    "- [ ] –°—Ç–∞—Ç—å—è –ø—Ä–æ –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—é –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏ –µ—Å—Ç—å —É –ò–≤–∞–Ω–∞\n",
    "\n",
    "- [ ] –ü–µ—Ä–µ–¥–µ–ª—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ –∫–æ–º–ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—É—é –∏–≥—Ä—É\n",
    "\n",
    "- –Ω–µ–∞—Ä—Ö–∏–º–µ–¥–æ–≤—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, p-–∞–¥–∏—á–µ—Å–∫–∏–µ —á–∏—Å–ª–∞\n",
    "\n",
    "- [ ] –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ [github:CyberCat-Institute/open-game-engine](https://github.com/CyberCat-Institute/open-game-engine)\n",
    "\n",
    "\n",
    "======\n",
    "\n",
    "- [ ] –Ω–µ –ø—Ä–∞–≤–æ –≥–æ–ª–æ—Å–∞, –∞ –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –æ—Ç–∫–ª—é—á–∞–µ—Ç—Å—è\n",
    "\n",
    "- [ ] F1 Smape\n",
    "\n",
    "- [ ] —Å–¥–µ–ª–∞—Ç—å –∫ —Ç–∞–±–ª–∏—á–∫–∞–º –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–±–ª—é–¥–∞–µ–º —Ç–æ-—Ç–æ —Ç–æ-—Ç–æ\n",
    "\n",
    "## BACKLOG\n",
    "\n",
    "- [ ] –ü—Ä–∏–º–µ–Ω—è—Ç—å gradient dropout –∫ –ø–æ–ª–æ–≤–∏–Ω–µ —Å–µ—Ç–∏ –∏ –∫–æ –≤—Å–µ–π —Å–µ—Ç–∏\n",
    "- [ ] –í–∞—Ä—å–∏—Ä–æ–≤–∞—Ç—å —à—É–º –æ—Ç 0 –¥–æ 1 (–∞ –Ω–µ 2)\n",
    "- [ ] –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π —Ä–µ—à–∞–ª–∏ MNIST character recognition –Ω–∞ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã—Ö —Å–µ—Ç—è—Ö\n",
    "    - [ ] Reference: https://github.com/ranimeshehata/Feed-Forward-Neural-Network-on-MNIST\n",
    "\n",
    "- [ ] –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é *He* –≤–º–µ—Å—Ç–æ *Xavier*\n",
    "  - [ ] –°—Ä–∞–≤–Ω–∏—Ç—å\n",
    "- [ ] –ö–∞–∫ –æ—Ü–µ–Ω–∏—Ç—å —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å —Å–ª—É—á–∞–π–Ω–æ–π –≤–µ–ª–∏—á–∏–Ω—ã?\n",
    "- [ ] –ù–∞ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–º–µ–Ω—è—Ç—å –∫–ª–∞—Å—Å $q$ –Ω–∞ –∫–ª–∞—Å—Å $r$ —Å –∑–∞–¥–∞–Ω–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é, –∞ –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —à—É–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetric Mean Absolute Percentage Error (sMAPE)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error\n",
    "\n",
    "Common in time series forecasting\n",
    "\n",
    "$$ \\mathrm{SMAPE} = {100 \\over n}  \\sum_{t=1}^{n} {{ |F_t - A_t| }\\over{ (|A_t| + |F_t|)/2 }} $$\n",
    "\n",
    "- $A_t$ - actual value\n",
    "- $F_t$ - forecast value\n",
    "\n",
    "Implementation of sMAPE is avaiable in the `torchmetrics` library:\n",
    "https://torchmetrics.readthedocs.io/en/v1.0.0/regression/symmetric_mean_absolute_percentage_error.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2290)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics import SymmetricMeanAbsolutePercentageError\n",
    "\n",
    "target = torch.tensor([1, 10, 1e6])\n",
    "preds = torch.tensor([0.9, 15, 1.2e6])\n",
    "\n",
    "smape = SymmetricMeanAbsolutePercentageError()\n",
    "smape(preds, target) # tensor(0.2290)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583327812227765"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(preds, target) # 0.9583327812227765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset #9 {\n",
       "   name: \"294_satellite_image\"\n",
       "   learning_task: LearningTask(name='regression', criterion=MSELoss(), y_dtype=torch.float32)\n",
       "   classes_count: 1\n",
       "   target: \"target\"\n",
       "   _data: DatasetData(df=      attr1  attr2  attr3  attr4  attr5  attr6  attr7  attr8  attr9  attr10  \\\n",
       " 0      92.0  115.0  120.0   94.0   84.0  102.0  106.0   79.0   84.0   102.0   \n",
       " 1      84.0  102.0  106.0   79.0   84.0  102.0  102.0   83.0   80.0   102.0   \n",
       " 2      84.0  102.0  102.0   83.0   80.0  102.0  102.0   79.0   84.0    94.0   \n",
       " 3      80.0  102.0  102.0   79.0   84.0   94.0  102.0   79.0   80.0    94.0   \n",
       " 4      84.0   94.0  102.0   79.0   80.0   94.0   98.0   76.0   80.0   102.0   \n",
       " ...     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       " 6430   60.0   83.0   96.0   85.0   64.0   87.0  100.0   88.0   64.0    83.0   \n",
       " 6431   64.0   79.0  100.0   85.0   56.0   71.0   96.0   85.0   56.0    68.0   \n",
       " 6432   56.0   68.0   91.0   81.0   56.0   64.0   91.0   81.0   53.0    64.0   \n",
       " 6433   56.0   68.0   87.0   74.0   60.0   71.0   91.0   81.0   60.0    64.0   \n",
       " 6434   60.0   71.0   91.0   81.0   60.0   64.0  104.0   99.0   56.0    64.0   \n",
       " \n",
       "       ...  attr28  attr29  attr30  attr31  attr32  attr33  attr34  attr35  \\\n",
       " 0     ...   104.0    88.0   121.0   128.0   100.0    84.0   107.0   113.0   \n",
       " 1     ...   100.0    84.0   107.0   113.0    87.0    84.0    99.0   104.0   \n",
       " 2     ...    87.0    84.0    99.0   104.0    79.0    84.0    99.0   104.0   \n",
       " 3     ...    79.0    84.0    99.0   104.0    79.0    84.0   103.0   104.0   \n",
       " 4     ...    79.0    84.0   103.0   104.0    79.0    79.0   107.0   109.0   \n",
       " ...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 6430  ...    92.0    66.0    87.0   108.0    89.0    63.0    83.0   104.0   \n",
       " 6431  ...    85.0    66.0    83.0   100.0    85.0    63.0    83.0   100.0   \n",
       " 6432  ...    81.0    59.0    87.0    96.0    81.0    63.0    83.0    92.0   \n",
       " 6433  ...    74.0    59.0    83.0    92.0    74.0    59.0    83.0    92.0   \n",
       " 6434  ...    74.0    59.0    83.0    92.0    70.0    63.0    79.0   108.0   \n",
       " \n",
       "       attr36  target  \n",
       " 0       87.0     3.0  \n",
       " 1       79.0     3.0  \n",
       " 2       79.0     3.0  \n",
       " 3       79.0     3.0  \n",
       " 4       87.0     3.0  \n",
       " ...      ...     ...  \n",
       " 6430    85.0     1.0  \n",
       " 6431    81.0     1.0  \n",
       " 6432    74.0     5.0  \n",
       " 6433    70.0     5.0  \n",
       " 6434    92.0     5.0  \n",
       " \n",
       " [6435 rows x 37 columns], train_df=      attr1  attr2  attr3  attr4  attr5  attr6  attr7  attr8  attr9  attr10  \\\n",
       " 651    42.0   30.0  140.0  150.0   42.0   30.0  135.0  150.0   42.0    30.0   \n",
       " 835    46.0   36.0  122.0  121.0   46.0   36.0  118.0  125.0   46.0    34.0   \n",
       " 6015   52.0   71.0   84.0   78.0   56.0   75.0   92.0   74.0   56.0    79.0   \n",
       " 2629   67.0   88.0   89.0   69.0   67.0   84.0   85.0   62.0   63.0    79.0   \n",
       " 471    43.0   31.0  128.0  135.0   46.0   34.0  133.0  132.0   43.0    31.0   \n",
       " ...     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       " 367    89.0  106.0  105.0   87.0   85.0  102.0  110.0   83.0   85.0   102.0   \n",
       " 1934   63.0   72.0   74.0   58.0   67.0   75.0   74.0   58.0   71.0    75.0   \n",
       " 4650   48.0   32.0  128.0  129.0   48.0   37.0  123.0  125.0   59.0    58.0   \n",
       " 3530   78.0   97.0   97.0   76.0   82.0  102.0  105.0   80.0   85.0   106.0   \n",
       " 4633   84.0   99.0  108.0   85.0   84.0  103.0  113.0   88.0   88.0   107.0   \n",
       " \n",
       "       ...  attr28  attr29  attr30  attr31  attr32  attr33  attr34  attr35  \\\n",
       " 651   ...   142.0    44.0    29.0   136.0   146.0    44.0    31.0   136.0   \n",
       " 835   ...   118.0    46.0    34.0   112.0   114.0    46.0    34.0   112.0   \n",
       " 6015  ...    80.0    53.0    84.0    97.0    80.0    57.0    84.0    93.0   \n",
       " 2629  ...    74.0    71.0    87.0    87.0    70.0    68.0    83.0    87.0   \n",
       " 471   ...   125.0    46.0    34.0   122.0   125.0    46.0    32.0   117.0   \n",
       " ...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 367   ...    85.0    88.0   107.0   113.0    88.0    88.0   107.0   118.0   \n",
       " 1934  ...    57.0    63.0    73.0    75.0    57.0    63.0    73.0    79.0   \n",
       " 4650  ...   127.0    46.0    34.0   124.0   124.0    46.0    37.0   119.0   \n",
       " 3530  ...    92.0    88.0   107.0   113.0    92.0    88.0   107.0   113.0   \n",
       " 4633  ...    85.0    82.0   100.0   104.0    85.0    90.0   104.0   108.0   \n",
       " \n",
       "       attr36  target  \n",
       " 651    142.0     2.0  \n",
       " 835    111.0     2.0  \n",
       " 6015    76.0     1.0  \n",
       " 2629    63.0     7.0  \n",
       " 471    129.0     2.0  \n",
       " ...      ...     ...  \n",
       " 367     88.0     3.0  \n",
       " 1934    57.0     7.0  \n",
       " 4650   127.0     2.0  \n",
       " 3530    88.0     3.0  \n",
       " 4633    85.0     3.0  \n",
       " \n",
       " [5148 rows x 37 columns], test_df=      attr1  attr2  attr3  attr4  attr5  attr6  attr7  attr8  attr9  attr10  \\\n",
       " 3691   46.0   48.0   96.0  103.0   43.0   36.0  104.0  121.0   43.0    34.0   \n",
       " 1148   72.0   81.0   90.0   65.0   72.0   81.0   94.0   65.0   64.0    69.0   \n",
       " 649    52.0   45.0  110.0  109.0   46.0   40.0  119.0  139.0   42.0    30.0   \n",
       " 5218   67.0   73.0   79.0   57.0   67.0   73.0   75.0   60.0   67.0    73.0   \n",
       " 3618   60.0   94.0  102.0   87.0   60.0   98.0  111.0   87.0   60.0    94.0   \n",
       " ...     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       " 6219   88.0  102.0  102.0   79.0   80.0   98.0   98.0   76.0   80.0    98.0   \n",
       " 3589   88.0  102.0  115.0   87.0   84.0  106.0  115.0   91.0   84.0   102.0   \n",
       " 6424   71.0  103.0  118.0   92.0   71.0  103.0  118.0   96.0   68.0   107.0   \n",
       " 5791   76.0   89.0   94.0   72.0   80.0   94.0   94.0   72.0   80.0    94.0   \n",
       " 3570   67.0  106.0  119.0   97.0   70.0  111.0  119.0   97.0   63.0   102.0   \n",
       " \n",
       "       ...  attr28  attr29  attr30  attr31  attr32  attr33  attr34  attr35  \\\n",
       " 3691  ...   107.0    46.0    43.0   112.0   122.0    49.0    49.0   112.0   \n",
       " 1148  ...    71.0    75.0    87.0    85.0    71.0    71.0    83.0    89.0   \n",
       " 649   ...   131.0    50.0    40.0   115.0   113.0    50.0    46.0   111.0   \n",
       " 5218  ...    61.0    64.0    73.0    86.0    61.0    64.0    73.0    78.0   \n",
       " 3618  ...    92.0    59.0    91.0   104.0    87.0    55.0    87.0   104.0   \n",
       " ...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 6219  ...    83.0    84.0    95.0   100.0    79.0    79.0    99.0    96.0   \n",
       " 3589  ...    87.0    93.0   107.0   113.0    92.0    88.0   107.0   113.0   \n",
       " 6424  ...    92.0    70.0   109.0   117.0    96.0    70.0   100.0   108.0   \n",
       " 5791  ...    75.0    79.0    87.0    93.0    71.0    75.0    91.0    96.0   \n",
       " 3570  ...    96.0    71.0   112.0   122.0   103.0    68.0   112.0   122.0   \n",
       " \n",
       "       attr36  target  \n",
       " 3691   118.0     2.0  \n",
       " 1148    75.0     7.0  \n",
       " 649    116.0     2.0  \n",
       " 5218    57.0     7.0  \n",
       " 3618    87.0     1.0  \n",
       " ...      ...     ...  \n",
       " 6219    79.0     3.0  \n",
       " 3589    87.0     3.0  \n",
       " 6424    92.0     1.0  \n",
       " 5791    75.0     4.0  \n",
       " 3570    92.0     1.0  \n",
       " \n",
       " [1287 rows x 37 columns], train_dataset=<torch.utils.data.dataset.TensorDataset object at 0x15ad47bf0>, test_dataset=<torch.utils.data.dataset.TensorDataset object at 0x15b0ce5d0>, train_loader=<torch.utils.data.dataloader.DataLoader object at 0x15b0cf470>, test_loader=<torch.utils.data.dataloader.DataLoader object at 0x15b0cec30>)\n",
       " },\n",
       " Dataset #10 {\n",
       "   name: \"573_cpu_act\"\n",
       "   learning_task: LearningTask(name='regression', criterion=MSELoss(), y_dtype=torch.float32)\n",
       "   classes_count: 1\n",
       "   target: \"target\"\n",
       "   _data: DatasetData(df=      lread  lwrite   scall  sread  swrite   fork       exec     rchar  \\\n",
       " 0       6.0     2.0  1036.0  103.0   114.0   1.00   1.000000  172076.0   \n",
       " 1       1.0     0.0  2165.0  205.0   101.0   0.40   1.200000   43107.0   \n",
       " 2      62.0    77.0  3806.0  258.0   166.0   1.40   1.400000  492142.0   \n",
       " 3       5.0     0.0  4721.0  256.0   177.0   0.99   2.580000  524787.0   \n",
       " 4      42.0    55.0  3949.0  249.0   244.0   2.60   4.600000  197289.0   \n",
       " ...     ...     ...     ...    ...     ...    ...        ...       ...   \n",
       " 8187   74.0    49.0  2688.0  176.0   103.0  11.00  32.200001   57714.0   \n",
       " 8188   29.0    40.0  1906.0  118.0    90.0   0.80   2.000000    8175.0   \n",
       " 8189    3.0     0.0   926.0   90.0    67.0   0.60   1.000000    5411.0   \n",
       " 8190    4.0     0.0   418.0   30.0    29.0   0.80   1.000000    3959.0   \n",
       " 8191    5.0     0.0  1888.0  248.0   215.0   6.20   1.800000  216420.0   \n",
       " \n",
       "          wchar  pgout  ...      pgscan  atch       pgin      ppgin  \\\n",
       " 0     355965.0   0.00  ...    0.000000  0.00   2.000000   4.000000   \n",
       " 1      44139.0   4.80  ...  181.399994  0.20  85.400002  88.199997   \n",
       " 2     268706.0   4.80  ...   79.199997  2.20   7.600000  12.200000   \n",
       " 3     174964.0  14.51  ...  189.860001  1.99   4.170000  24.850000   \n",
       " 4     529200.0   4.20  ...    0.000000  1.40   1.800000   2.200000   \n",
       " ...        ...    ...  ...         ...   ...        ...        ...   \n",
       " 8187   38484.0   0.80  ...    0.000000  0.00   0.800000   0.800000   \n",
       " 8188   27313.0   0.00  ...    0.000000  0.00   0.800000   0.800000   \n",
       " 8189   19322.0   0.00  ...    0.000000  0.40   0.400000   0.400000   \n",
       " 8190   10679.0   0.00  ...    0.000000  0.00   0.200000   0.200000   \n",
       " 8191   39346.0   0.00  ...    0.000000  0.00   7.400000  14.800000   \n",
       " \n",
       "             pflt        vflt  runqsz  freemem   freeswap  target  \n",
       " 0      73.599998   89.000000     2.0   6527.0  1851864.0    90.0  \n",
       " 1      19.400000  161.800003     3.0    130.0  1131931.0    88.0  \n",
       " 2      68.000000  218.800003     5.2    256.0  1314590.0    85.0  \n",
       " 3      95.629997  248.910004     1.0    233.0   972606.0    81.0  \n",
       " 4     219.600006  297.200012     3.4    331.0  1013805.0    79.0  \n",
       " ...          ...         ...     ...      ...        ...     ...  \n",
       " 8187  343.200012  649.400024     7.0    314.0  1096333.0    69.0  \n",
       " 8188   56.200001   78.599998     3.6    166.0  1107088.0    88.0  \n",
       " 8189   53.400002  154.000000     1.0   1177.0  1020400.0    92.0  \n",
       " 8190   61.000000   73.199997     2.4   6355.0  1702592.0    96.0  \n",
       " 8191  296.600006  420.200012     4.6   1628.0  1757696.0    80.0  \n",
       " \n",
       " [8192 rows x 22 columns], train_df=      lread  lwrite   scall  sread  swrite   fork       exec     rchar  \\\n",
       " 4780   47.0    65.0  3012.0  269.0   110.0   1.60   3.600000  913173.0   \n",
       " 5585    4.0     0.0  1917.0  195.0   155.0   1.60   0.600000   89080.0   \n",
       " 7973    1.0     0.0   304.0   58.0    46.0   0.20   0.200000    1397.0   \n",
       " 50      0.0     0.0   255.0   32.0    32.0   0.20   0.200000    1430.0   \n",
       " 155    15.0    15.0   419.0  189.0    62.0   0.20   0.200000  322341.0   \n",
       " ...     ...     ...     ...    ...     ...    ...        ...       ...   \n",
       " 1934    1.0     0.0   864.0   67.0    65.0   0.20   0.200000    4103.0   \n",
       " 4650   83.0    68.0  5019.0  529.0   453.0  11.98  19.559999  259917.0   \n",
       " 3530   21.0     1.0  5989.0  673.0   474.0   7.58   3.790000  505990.0   \n",
       " 4633    6.0     1.0  2745.0  152.0   117.0   1.00   3.800000   12744.0   \n",
       " 7256    4.0     2.0  1036.0   64.0    51.0   0.40   0.600000  101463.0   \n",
       " \n",
       "          wchar  pgout  ...     pgscan  atch   pgin  ppgin        pflt  \\\n",
       " 4780   28574.0   7.80  ...  86.400002  0.40  10.20  10.60  117.800003   \n",
       " 5585   73434.0   0.00  ...   0.000000  0.00   0.60   0.80   80.239998   \n",
       " 7973   10710.0   1.80  ...   0.000000  0.20   0.00   0.00   16.799999   \n",
       " 50      7410.0   0.00  ...   0.000000  0.00   0.00   0.00   15.600000   \n",
       " 155   310319.0   0.00  ...   0.000000  0.00   0.00   0.00   15.600000   \n",
       " ...        ...    ...  ...        ...   ...    ...    ...         ...   \n",
       " 1934   20315.0   0.00  ...   0.000000  0.00   0.60   0.60   15.770000   \n",
       " 4650   42539.0   6.99  ...   6.590000  5.59  13.57  15.37  536.130005   \n",
       " 3530   66850.0   0.00  ...   0.000000  0.00   2.40   2.59  381.239990   \n",
       " 4633   32916.0   0.00  ...   0.000000  0.20  12.40  12.60   55.799999   \n",
       " 7256   32561.0   1.40  ...   2.200000  4.40   0.60   0.80   30.799999   \n",
       " \n",
       "             vflt  runqsz  freemem   freeswap  target  \n",
       " 4780  207.600006     1.0    151.0  1088790.0    83.0  \n",
       " 5585  179.839996     1.0   1156.0  1013640.0    90.0  \n",
       " 7973   20.799999     1.2    225.0  1759638.0    98.0  \n",
       " 50     16.799999     1.6   1196.0  1767021.0    91.0  \n",
       " 155    17.000000     2.4   5333.0  1825789.0    97.0  \n",
       " ...          ...     ...      ...        ...     ...  \n",
       " 1934   21.959999     3.8    232.0  1087649.0    97.0  \n",
       " 4650  873.049988     5.8    233.0  1091556.0    53.0  \n",
       " 3530  559.080017     6.8    809.0  1526997.0    70.0  \n",
       " 4633   99.400002     1.0   1343.0  1113069.0    89.0  \n",
       " 7256   71.400002     2.2    138.0  1523264.0    96.0  \n",
       " \n",
       " [6553 rows x 22 columns], test_df=      lread  lwrite   scall  sread  swrite  fork  exec     rchar     wchar  \\\n",
       " 6294   27.0     0.0  2052.0  163.0    87.0  6.60  19.4  536165.0   28955.0   \n",
       " 380     1.0     1.0   394.0  208.0    51.0  0.20   0.2  379080.0  332905.0   \n",
       " 88      4.0     0.0  2921.0  248.0   205.0  3.80   1.4  140416.0   21712.0   \n",
       " 4202    6.0     2.0  2712.0  259.0   301.0  3.19   1.0   91310.0   26600.0   \n",
       " 287    15.0     2.0  2374.0  132.0   121.0  0.40   0.8   30493.0   41061.0   \n",
       " ...     ...     ...     ...    ...     ...   ...   ...       ...       ...   \n",
       " 5003    7.0     1.0  3865.0  191.0   179.0  1.60   3.8  186277.0  146745.0   \n",
       " 6959    8.0     1.0  1652.0  298.0   221.0  5.60   1.8  275926.0  146174.0   \n",
       " 4798    8.0     7.0  1608.0   79.0    67.0  0.20   0.2   16265.0   17578.0   \n",
       " 4865   69.0    90.0  3175.0  109.0   128.0  1.00   1.6   66150.0  121835.0   \n",
       " 1617    2.0     0.0   667.0  131.0   141.0  1.40   4.8    2185.0   12395.0   \n",
       " \n",
       "       pgout  ...      pgscan  atch       pgin      ppgin        pflt  \\\n",
       " 6294   6.80  ...  151.600006   0.4  64.599998  69.599998  217.399994   \n",
       " 380    0.00  ...    0.000000   0.0   0.000000   0.000000   15.600000   \n",
       " 88     3.00  ...    0.000000   0.4   1.000000   1.400000  208.800003   \n",
       " 4202   1.20  ...    0.000000   0.4   2.400000   2.400000  160.479996   \n",
       " 287   11.42  ...  164.729996   0.4  15.830000  26.450001   55.110001   \n",
       " ...     ...  ...         ...   ...        ...        ...         ...   \n",
       " 5003   0.00  ...    0.000000   0.0   3.400000   4.400000  133.800003   \n",
       " 6959   0.00  ...    0.000000   0.0   0.000000   0.000000  257.200012   \n",
       " 4798   0.00  ...    0.000000   0.0   2.400000   2.400000   38.000000   \n",
       " 4865   0.00  ...    0.000000   0.0   7.400000   9.400000   59.599998   \n",
       " 1617   0.00  ...    0.000000   0.0   0.000000   0.000000   98.800003   \n",
       " \n",
       "             vflt  runqsz  freemem   freeswap  target  \n",
       " 6294  479.799988     2.0    126.0  1089085.0    74.0  \n",
       " 380    16.799999     2.6   5746.0  1834560.0    97.0  \n",
       " 88    328.600006     3.0    177.0  1437750.0    86.0  \n",
       " 4202  250.500000     1.5    304.0  1032599.0    87.0  \n",
       " 287   184.369995     3.0    150.0  1018368.0    91.0  \n",
       " ...          ...     ...      ...        ...     ...  \n",
       " 5003  202.000000     4.2    825.0  1515533.0    76.0  \n",
       " 6959  366.200012     2.4   5155.0  1836584.0    84.0  \n",
       " 4798   87.599998     3.0    691.0   978082.0    94.0  \n",
       " 4865   88.800003     3.8    735.0  1519203.0    80.0  \n",
       " 1617   79.199997     1.0   7617.0  1879974.0    95.0  \n",
       " \n",
       " [1639 rows x 22 columns], train_dataset=<torch.utils.data.dataset.TensorDataset object at 0x15bfeefc0>, test_dataset=<torch.utils.data.dataset.TensorDataset object at 0x15c03bd70>, train_loader=<torch.utils.data.dataloader.DataLoader object at 0x15c039970>, test_loader=<torch.utils.data.dataloader.DataLoader object at 0x15c039c40>)\n",
       " }]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cgtnnlib.LearningTask import is_regression_task\n",
    "import cgtnnlib.datasets as ds\n",
    "\n",
    "# list(filter(lambda x: is_regression_task(x.learning_task), ds.datasets))\n",
    "[ds.datasets[8], ds.datasets[9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setup complete'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from cgtnnlib.Dataset import Dataset\n",
    "from cgtnnlib.constants import LEARNING_RATE, RANDOM_STATE\n",
    "import cgtnnlib.training as tr\n",
    "import cgtnnlib.datasets as ds\n",
    "from cgtnnlib.NoiseGenerator import NoiseGenerator, target_dispersion_scaled_noise, stable_noise, no_noise_generator\n",
    "\n",
    "iterations = 10\n",
    "\"–ß–∏—Å–ª–æ –º–æ–¥–µ–ª–µ–π –≤ –∫–∞–∂–¥–æ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ\"\n",
    "\n",
    "pp = [0.0, 0.5, 0.9]\n",
    "\"–ù–∞–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ gradient dropout\"\n",
    "\n",
    "hidden_layers_count = 5\n",
    "\"–ß–∏—Å–ª–æ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—ë–≤\"\n",
    "\n",
    "inner_layer_size = 150\n",
    "\"–ß–∏—Å–ª–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö\"\n",
    "\n",
    "datasets = [ds.datasets[2], ds.datasets[5], ds.datasets[8], ds.datasets[9]]\n",
    "\"–ù–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–æ–≤–æ–¥–∏—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\"\n",
    "\n",
    "#output_dir = 'rev9' #3 layers\n",
    "#output_dir = 'rev9.2' #5 layers\n",
    "output_dir = 'rev9.3' #5 layers, \n",
    "\"–ü–∞–ø–∫–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\"\n",
    "\n",
    "def dir_path(d: Dataset, p: float, n: NoiseGenerator):\n",
    "    \"–ü—É—Ç—å –∫–∞—Ç–∞–ª–æ–≥–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\"\n",
    "    return f'{output_dir}/dataset{d.number}_p{p}_noise{n.name}/'\n",
    "\n",
    "def model_path(d: Dataset, p: float, n: NoiseGenerator, N: int):\n",
    "    \"–ü—É—Ç—å —Ñ–∞–π–ª–∞ PyTorch –º–æ–¥–µ–ª–∏ (`.pth`)\"\n",
    "    return f'{output_dir}/dataset{d.number}_p{p}_noise{n.name}/{N}.pth'\n",
    "\n",
    "def report_filename(d: Dataset, p: float, n: NoiseGenerator, N: int):\n",
    "    \"–ò–º—è —Ñ–∞–π–ª–∞ –æ—Ç—á—ë—Ç–∞ (`.json`, —Å–º. `cgtnnlib/Report.py`)\"\n",
    "    return f'dataset{d.number}_p{p}_noise{n.name}/{N}.json'\n",
    "\n",
    "def report_path(d: Dataset, p: float, n: NoiseGenerator, N: int):\n",
    "    \"–ü—É—Ç—å —Ñ–∞–π–ª–∞ –æ—Ç—á—ë—Ç–∞ (`.json`, —Å–º. `cgtnnlib/Report.py`)\"\n",
    "    return f'{output_dir}/{report_filename(d, p, n, N)}'\n",
    "\n",
    "def epochs_for_dataset(dataset: Dataset):\n",
    "    return 10\n",
    "\n",
    "\n",
    "ng_makers: list[Callable[[Dataset], NoiseGenerator]] = [\n",
    "    lambda _: no_noise_generator,\n",
    "    lambda d: target_dispersion_scaled_noise(\n",
    "        dataset=d,\n",
    "        factor=0.03,\n",
    "        random_seed=RANDOM_STATE + 1,\n",
    "    ),\n",
    "    lambda d: stable_noise(\n",
    "        dataset=d,\n",
    "        factor=0.03,\n",
    "        alpha=1,\n",
    "        beta=0,\n",
    "    ),\n",
    "    lambda d: stable_noise(\n",
    "        dataset=d,\n",
    "        factor=0.03,\n",
    "        alpha=1.12,\n",
    "        beta=0,\n",
    "    ),\n",
    "    lambda d: stable_noise(\n",
    "        dataset=d,\n",
    "        factor=0.03,\n",
    "        alpha=2.0,\n",
    "        beta=1,\n",
    "    ),\n",
    "]\n",
    "\"–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã —à—É–º–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ—à–∏–≤–∞–Ω–∏—è –∫–æ –≤—Ö–æ–¥–∞–º\"\n",
    "\n",
    "'setup complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–Ø –Ω–µ –ø–æ–Ω–∏–º–∞—é, –ø–æ—á–µ–º—É –º—ã –ø—Ä–∏–º–µ—à–∏–≤–∞–µ–º —à—É–º –∏–º–µ–Ω–Ω–æ –∫–æ –≤—Ö–æ–¥–∞–º.\n",
    "–ú–æ–∂–µ—Ç, —Ç–∞–º –∏ –Ω–µ —Ç–∞–∫ –≤—Å—ë –¥–µ–ª–∞–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Model B\n",
    "\n",
    "- both take ~5m 06s to train 10 iterations\n",
    "- both on both noises: about ~10m\n",
    "\n",
    "<hr>\n",
    "\n",
    "- `ds.datasets['StudentPerformanceFactors']` takes ~2m 30s to train 10 iterations\n",
    "- `ds.datasets['wine_quality']` takes ~2m 36s to train 10 iterations\n",
    "\n",
    "<hr>\n",
    "\n",
    "- `ds.datasets['allhyper']` takes ~36m to train on all noise generators\n",
    "\n",
    "### Model B*\n",
    "\n",
    "3 hidden layers:\n",
    "- ~15m 38s: Dataset #3, 10 epochs, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ \n",
    "- ~9m 30s: Dataset #3, 10 epochs, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ \n",
    "\n",
    "5 hidden layers:\n",
    "- ~14m 10s: Dataset #3, 10 epochs, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ \n",
    "\n",
    "- ~93m 23s: Datasets {#3, #6, #9, #10}, 10 epochs, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ \n",
    "- ~147m 33s: Datasets {#3, #6, #9, #10}, 20 epochs, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fast training\n",
    "\n",
    "# import os\n",
    "\n",
    "# from cgtnnlib.Report import Report\n",
    "# from cgtnnlib.nn.AugmentedReLUNetworkMultilayer import AugmentedReLUNetworkMultilayer\n",
    "\n",
    "# dataset = ds.datasets['1030_ERA']\n",
    "# p = 0.5\n",
    "# noise_generator = no_noise_generator\n",
    "# epochs = 10\n",
    "\n",
    "# for iteration in range(iterations):\n",
    "#     os.makedirs(dir_path(dataset, p, noise_generator), exist_ok=True)\n",
    "#     report = Report(\n",
    "#         dir=output_dir,\n",
    "#         filename=report_filename(d=dataset, p=p,\n",
    "#                                     n=noise_generator, N=iteration)\n",
    "#     )\n",
    "#     tr.super_train_model(\n",
    "#         make_model=lambda: AugmentedReLUNetworkMultilayer(\n",
    "#             inputs_count=dataset.features_count,\n",
    "#             outputs_count=dataset.classes_count,\n",
    "#             p=p,\n",
    "#             inner_layer_size=inner_layer_size,\n",
    "#             hidden_layers_count=hidden_layers_count,\n",
    "#         ),\n",
    "#         model_path=model_path(d=dataset, p=p,\n",
    "#                                 n=noise_generator, N=iteration),\n",
    "#         dataset=dataset,\n",
    "#         report=report,\n",
    "#         epochs=epochs_for_dataset(dataset),\n",
    "#         learning_rate=LEARNING_RATE,\n",
    "#         dry_run=False,\n",
    "#         iteration=iteration,\n",
    "#         noise_generator=noise_generator,\n",
    "#     )\n",
    "\n",
    "# 'training complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=9 #10 gStable10A2.0B1F0.03 p=0.9 E9/10 S67 Loss=0.0407@AugmentedReLUNetworkMultilayer\n",
      "create_and_train_model(): saved model to rev9.3/dataset10_p0.9_noiseStable10A2.0B1F0.03/9.pth\n",
      "Report saved to rev9.3/dataset10_p0.9_noiseStable10A2.0B1F0.03/9.json.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'training complete'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training\n",
    "\n",
    "import os\n",
    "\n",
    "from cgtnnlib.Report import Report\n",
    "from cgtnnlib.nn.AugmentedReLUNetworkMultilayer import AugmentedReLUNetworkMultilayer\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for ng_maker in ng_makers:\n",
    "        for p in pp:\n",
    "            noise_generator = ng_maker(dataset)\n",
    "            for iteration in range(iterations):\n",
    "                os.makedirs(dir_path(dataset, p, noise_generator), exist_ok=True)\n",
    "                report = Report(\n",
    "                    dir=output_dir,\n",
    "                    filename=report_filename(d=dataset, p=p,\n",
    "                                             n=noise_generator, N=iteration)\n",
    "                )\n",
    "                tr.super_train_model(\n",
    "                    make_model=lambda: AugmentedReLUNetworkMultilayer(\n",
    "                        inputs_count=dataset.features_count,\n",
    "                        outputs_count=dataset.classes_count,\n",
    "                        p=p,\n",
    "                        inner_layer_size=inner_layer_size,\n",
    "                        hidden_layers_count=hidden_layers_count,\n",
    "                    ),\n",
    "                    model_path=model_path(d=dataset, p=p,\n",
    "                                          n=noise_generator, N=iteration),\n",
    "                    dataset=dataset,\n",
    "                    report=report,\n",
    "                    epochs=epochs_for_dataset(dataset),\n",
    "                    learning_rate=LEARNING_RATE,\n",
    "                    dry_run=False,\n",
    "                    iteration=iteration,\n",
    "                    noise_generator=noise_generator,\n",
    "                )\n",
    "\n",
    "'training complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation & Analysis\n",
    "\n",
    "~2m 44s: Dataset #3, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ \n",
    "\n",
    "~15m 32s: Datasets {#3, #6, #9, #10}, 5 ng_makers, $p \\in \\{ 0.0, 0.5, 0.9 \\} $ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## A single evaluation for quick evaluations\n",
    "\n",
    "# dataset = ds.datasets['1030_ERA']\n",
    "# noise_generator = no_noise_generator\n",
    "# p = 0.5\n",
    "\n",
    "# ax_drawer = make_ax_drawer(\n",
    "#     dataset=dataset,\n",
    "#     title=f'Dataset #{dataset.number}: {dataset.name}, {noise_generator.name}, p = {p}',\n",
    "#     get_report_path=lambda N: report_path(dataset, p,\n",
    "#                                           noise_generator, N),\n",
    "#     get_model_path=lambda N: model_path(dataset, p,\n",
    "#                                         noise_generator, N),\n",
    "#     p=p,\n",
    "#     metric='mse',\n",
    "# )\n",
    "\n",
    "# ax_drawer(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:135: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:135: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<string>:135: SyntaxWarning: invalid escape sequence '\\{'\n",
      "<>:135: SyntaxWarning: invalid escape sequence '\\{'\n",
      "/var/folders/m9/y193wddj505gjbgjyvhjmzjm0000gq/T/ipykernel_70223/3827557607.py:135: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  fig.suptitle(f'Dataset #{dataset.number}: {dataset.name}\\{MODEL_TYPE.__name__}', fontsize=16)\n",
      "/var/folders/m9/y193wddj505gjbgjyvhjmzjm0000gq/T/ipykernel_70223/3827557607.py:135: SyntaxWarning: invalid escape sequence '\\{'\n",
      "  fig.suptitle(f'Dataset #{dataset.number}: {dataset.name}\\{MODEL_TYPE.__name__}', fontsize=16)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_ax_drawer() got an unexpected keyword argument 'get_report_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 101\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw_ax\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m## A plot grid for multiple experiment evaluations\u001b[39;00m\n\u001b[1;32m     99\u001b[0m ax_drawers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    100\u001b[0m     [[\n\u001b[0;32m--> 101\u001b[0m         \u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnoise_generator\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_ax_drawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnoise_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, p = \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_report_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mnoise_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mnoise_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_generator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mng_maker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pp\n\u001b[1;32m    112\u001b[0m     ] \u001b[38;5;28;01mfor\u001b[39;00m ng_maker \u001b[38;5;129;01min\u001b[39;00m ng_makers]\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets\n\u001b[1;32m    114\u001b[0m ]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(ax_drawers)\n\u001b[1;32m    117\u001b[0m (nrows, ncols) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mlen\u001b[39m(ax_drawers[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mlen\u001b[39m(ax_drawers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    120\u001b[0m )\n",
      "Cell \u001b[0;32mIn[28], line 101\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(noise_generator)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m draw_ax\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m## A plot grid for multiple experiment evaluations\u001b[39;00m\n\u001b[1;32m     99\u001b[0m ax_drawers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    100\u001b[0m     [[\n\u001b[0;32m--> 101\u001b[0m         (\u001b[38;5;28;01mlambda\u001b[39;00m noise_generator: \u001b[43mmake_ax_drawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnoise_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, p = \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_report_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mnoise_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mnoise_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m)(noise_generator\u001b[38;5;241m=\u001b[39mng_maker(dataset))\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pp\n\u001b[1;32m    112\u001b[0m     ] \u001b[38;5;28;01mfor\u001b[39;00m ng_maker \u001b[38;5;129;01min\u001b[39;00m ng_makers]\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets\n\u001b[1;32m    114\u001b[0m ]\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(ax_drawers)\n\u001b[1;32m    117\u001b[0m (nrows, ncols) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mlen\u001b[39m(ax_drawers[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mlen\u001b[39m(ax_drawers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    120\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: make_ax_drawer() got an unexpected keyword argument 'get_report_path'"
     ]
    }
   ],
   "source": [
    "## Single Plot Analysis\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cgtnnlib.Report import Report\n",
    "from cgtnnlib.LearningTask import is_classification_task\n",
    "from cgtnnlib.analyze import plot_deviant_curves_on_ax_or_plt\n",
    "from cgtnnlib.constants import NOISE_FACTORS\n",
    "from cgtnnlib.evaluate import eval_report_at_path, super_eval_model\n",
    "from cgtnnlib.nn.AugmentedReLUNetworkMultilayer import AugmentedReLUNetworkMultilayer\n",
    "\n",
    "MODEL_TYPE = AugmentedReLUNetworkMultilayer\n",
    "\n",
    "\n",
    "def read_json(path: str) -> dict:\n",
    "    with open(path) as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def summarize_series_list(series_list: list[pd.Series]):\n",
    "    df = pd.DataFrame(series_list).T\n",
    "\n",
    "    summary_df = pd.DataFrame({\n",
    "        0.25: df.quantile(0.25, axis=1),\n",
    "        0.75: df.quantile(0.75, axis=1),\n",
    "        'mean': df.mean(axis=1),\n",
    "    })\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "def make_ax_drawer(\n",
    "    dataset: Dataset,\n",
    "    title: str,\n",
    "    get_report_and_model_path: Callable[[int], tuple[str, str]],\n",
    "    p: float,\n",
    "    metric: str,\n",
    "):\n",
    "    def read_eval_from_iteration(n) -> pd.DataFrame:\n",
    "        (report_path, model_path) = get_report_and_model_path(n)\n",
    "        report = Report.from_path(report_path)\n",
    "        \n",
    "        model = MODEL_TYPE(\n",
    "            inputs_count=dataset.features_count,\n",
    "            outputs_count=dataset.classes_count,\n",
    "            p=p,\n",
    "            inner_layer_size=inner_layer_size,\n",
    "            hidden_layers_count=hidden_layers_count,\n",
    "        )\n",
    "        model.eval()\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        super_eval_model(\n",
    "            dataset=dataset,\n",
    "            model=model,\n",
    "            report=report,\n",
    "        )\n",
    "        print('read_eval_from_iteration', report_path, n)\n",
    "        return pd.DataFrame(read_json(report_path)['eval'])\n",
    "    \n",
    "    def read_loss_from_iteration(n) -> pd.DataFrame:\n",
    "        (report_path, model_path) = get_report_and_model_path(n)\n",
    "        json = read_json(report_path)\n",
    "        return pd.DataFrame({ 'loss': json['loss'] })\n",
    "\n",
    "    files = [\n",
    "        read_eval_from_iteration(n)\n",
    "        for n in range(iterations)\n",
    "    ]\n",
    "            \n",
    "    print(f'Processing {get_report_and_model_path(0)}...')\n",
    "\n",
    "    curve = summarize_series_list([file[metric] for file in files])\n",
    "\n",
    "    def draw_ax(ax):\n",
    "        plot_deviant_curves_on_ax_or_plt(\n",
    "            ax_or_plt=ax,\n",
    "            models=[{\n",
    "                'curve': curve,\n",
    "                'color': 'purple',\n",
    "                'label': 'Mean',\n",
    "                'quantiles_color': 'pink',\n",
    "                'quantiles_label': 'Quartiles 0.25, 0.75', \n",
    "            }],\n",
    "            X=NOISE_FACTORS,\n",
    "            title=title,\n",
    "            xlabel='Noise amplitude',\n",
    "            ylabel=metric,\n",
    "            quantiles_alpha=0.5,\n",
    "        )\n",
    "    \n",
    "    return draw_ax\n",
    "\n",
    "## A plot grid for multiple experiment evaluations\n",
    "\n",
    "ax_drawers = [\n",
    "    [[\n",
    "        (lambda noise_generator: make_ax_drawer(\n",
    "            dataset=dataset,\n",
    "            title=f'{noise_generator.name}, p = {p}',\n",
    "            get_report_and_model_path=lambda N: (\n",
    "                report_path(dataset, p, noise_generator, N),\n",
    "                model_path(dataset, p, noise_generator, N)\n",
    "            ),\n",
    "            p=p,\n",
    "            metric='smape',\n",
    "        ))(noise_generator=ng_maker(dataset))\n",
    "        for p in pp\n",
    "    ] for ng_maker in ng_makers]\n",
    "    for dataset in datasets\n",
    "]\n",
    "\n",
    "print(ax_drawers)\n",
    "(nrows, ncols) = (\n",
    "    len(ax_drawers[0]),\n",
    "    len(ax_drawers[0][0]),\n",
    ")\n",
    "\n",
    "print(f'Size: {nrows}x{ncols}')\n",
    "\n",
    "figsize = (12, 20)\n",
    "\"(width, height), inches\"\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "\n",
    "    for j in range(nrows):\n",
    "        for k in range(ncols):\n",
    "            ax_drawers[i][j][k](axes[j, k])\n",
    "    \n",
    "    fig.suptitle(f'Dataset #{dataset.number}: {dataset.name}\\{MODEL_TYPE.__name__}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.01, 1, 0.95]) # rect adjusts space for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying 5 layers\n",
    "\n",
    "Smape goes down (p = 0):\n",
    "- 0.1 -> 0.08\n",
    "- 0.10 -> 0.085\n",
    "- 0.10 -> 0.085\n",
    "- 0.09 ~> 0.095 (goes up on Stble4A.12B0F0.03)\n",
    "- 0.11 -> 0.085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.abs(np.array([\n",
    "    0.1 - 0.08,\n",
    "    0.1 - 0.085,\n",
    "    0.10 - 0.085,\n",
    "    0.09 - 0.095,\n",
    "    0.11 - 0.085,\n",
    "])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we gain ~0.016 of sMAPE for adding 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322.8285714285714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 610 / 350 * 759\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Chambers, J. M., Mallows, C. L., & Stuck, B. W. (1976). A method for simulating stable random variables. *Journal of the American Statistical Association*, *71*(354), 340-344.\n",
    "2. M. Firouzi, A. Mohammadpour. A Survey on Simulating Stable Random Variables. URL: https://www.semanticscholar.org/reader/11a1e93642dc0a5c94e6906bcca5e4d25d4e9d46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
